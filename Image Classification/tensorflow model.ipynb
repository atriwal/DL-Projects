{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = {\n",
    "      'data_url': 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz',\n",
    "      'bottleneck_tensor_name': 'pool_3/_reshape:0',\n",
    "      'bottleneck_tensor_size': 2048,\n",
    "      'input_width': 299,\n",
    "      'input_height': 299,\n",
    "      'input_depth': 3,\n",
    "      'resized_input_tensor_name': 'Mul:0',\n",
    "      'model_file_name': 'classify_image_graph_def.pb',\n",
    "      'input_mean': 128,\n",
    "      'input_std': 128,\n",
    "      'quantize_layer': False,\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not extracting or downloading files, model already present in disk\n"
     ]
    }
   ],
   "source": [
    "dest_directory = 'pretrained_model'\n",
    "if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "data_url = model_info.get('data_url')\n",
    "filename = data_url.split('/')[-1]\n",
    "filepath = os.path.join(dest_directory, filename)\n",
    "if not os.path.exists(filepath):\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "        sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                       (filename,\n",
    "                        float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(data_url, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    tf.logging.info('Successfully downloaded', filename, statinfo.st_size,\n",
    "                    'bytes.')\n",
    "    print('Extracting file from ', filepath)\n",
    "    tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "else:\n",
    "    print('Not extracting or downloading files, model already present in disk')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model path:  pretrained_model/classify_image_graph_def.pb\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as graph:\n",
    "    model_path = os.path.join('pretrained_model', model_info['model_file_name'])\n",
    "    print('Model path: ', model_path)\n",
    "    with gfile.FastGFile(model_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        bottleneck_tensor, resized_input_tensor = (tf.import_graph_def(\n",
    "          graph_def,\n",
    "          name='',\n",
    "          return_elements=[\n",
    "              model_info['bottleneck_tensor_name'],\n",
    "              model_info['resized_input_tensor_name'],\n",
    "          ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = {}\n",
    "parent_dir = 'input/flower_photos/'\n",
    "for sub_dir in os.listdir(parent_dir):\n",
    "    images = os.listdir(parent_dir + '/' + sub_dir)\n",
    "    train, validate, test = np.split(images, [int(.6*len(images)), int(.8*len(images))])\n",
    "    image_list[sub_dir] = {\n",
    "        'dir': sub_dir,\n",
    "        'training': train,\n",
    "        'testing': validate,\n",
    "        'validation': test,\n",
    "    }\n",
    "class_count = len(image_list.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jpeg_decoding(input_width, input_height, input_depth, input_mean,input_std):\n",
    "    jpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')\n",
    "    decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\n",
    "    decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "    decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "    resize_shape = tf.stack([input_height, input_width])\n",
    "    resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\n",
    "    resized_image = tf.image.resize_bilinear(decoded_image_4d,resize_shape_as_int)\n",
    "    offset_image = tf.subtract(resized_image, input_mean)\n",
    "    mul_image = tf.multiply(offset_image, 1.0 / input_std)\n",
    "    return jpeg_data, mul_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir,\n",
    "                      jpeg_data_tensor, decoded_image_tensor,\n",
    "                      resized_input_tensor, bottleneck_tensor, architecture):\n",
    "    how_many_bottlenecks = 0\n",
    "    ensure_dir_exists(bottleneck_dir)\n",
    "    for label_name, label_lists in image_lists.items():\n",
    "        for category in ['training', 'testing', 'validation']:\n",
    "            category_list = label_lists[category]\n",
    "            for index, unused_base_name in enumerate(category_list):\n",
    "                get_or_create_bottleneck(\n",
    "                    sess, image_lists, label_name, index, image_dir, category,\n",
    "                    bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "                    resized_input_tensor, bottleneck_tensor, architecture)\n",
    "\n",
    "                how_many_bottlenecks += 1\n",
    "                if how_many_bottlenecks % 100 == 0:\n",
    "                    tf.logging.info(\n",
    "                      str(how_many_bottlenecks) + ' bottleneck files created.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_final_training_ops(class_count, final_tensor_name, bottleneck_tensor,\n",
    "                           bottleneck_tensor_size, quantize_layer):\n",
    "    with tf.name_scope('input'):\n",
    "        bottleneck_input = tf.placeholder_with_default(bottleneck_tensor,shape=[None, bottleneck_tensor_size],\n",
    "                                                       name='BottleneckInputPlaceholder')\n",
    "\n",
    "        ground_truth_input = tf.placeholder(tf.int64, [None], name='GroundTruthInput')\n",
    "\n",
    "  # Organizing the following ops as `final_training_ops` so they're easier\n",
    "  # to see in TensorBoard\n",
    "    \n",
    "    layer_name = 'final_training_ops'\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            initial_value = tf.truncated_normal(\n",
    "              [bottleneck_tensor_size, class_count], stddev=0.001)\n",
    "            layer_weights = tf.Variable(initial_value, name='final_weights')\n",
    "#             variable_summaries(layer_weights)\n",
    "        with tf.name_scope('biases'):\n",
    "            layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "#             variable_summaries(layer_biases)\n",
    "\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "            tf.summary.histogram('pre_activations', logits)\n",
    "\n",
    "    final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "\n",
    "    tf.summary.histogram('activations', final_tensor)\n",
    "\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy_mean = tf.losses.sparse_softmax_cross_entropy(labels=ground_truth_input, logits=logits)\n",
    "\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(FLAGS.learning_rate)\n",
    "        train_step = optimizer.minimize(cross_entropy_mean)\n",
    "\n",
    "    return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,\n",
    "          final_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            prediction = tf.argmax(result_tensor, 1)\n",
    "            correct_prediction = tf.equal(prediction, ground_truth_tensor)\n",
    "        with tf.name_scope('accuracy'):\n",
    "            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', evaluation_step)\n",
    "    return evaluation_step, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    \n",
    "    jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(\n",
    "        model_info['input_width'], model_info['input_height'],\n",
    "        model_info['input_depth'], model_info['input_mean'],\n",
    "        model_info['input_std'])\n",
    "    \n",
    "    cache_bottlenecks(sess, image_lists, FLAGS.image_dir,\n",
    "                        FLAGS.bottleneck_dir, jpeg_data_tensor,\n",
    "                        decoded_image_tensor, resized_image_tensor,\n",
    "                        bottleneck_tensor, FLAGS.architecture)\n",
    "    \n",
    "    (train_step, cross_entropy, bottleneck_input, ground_truth_input,\n",
    "     final_tensor) = add_final_training_ops(\n",
    "         len(image_lists.keys()), FLAGS.final_tensor_name, bottleneck_tensor,\n",
    "         model_info['bottleneck_tensor_size'], model_info['quantize_layer'])\n",
    "    \n",
    "    # Create the operations we need to evaluate the accuracy of our new layer.\n",
    "    evaluation_step, prediction = add_evaluation_step(\n",
    "        final_tensor, ground_truth_input)\n",
    "\n",
    "    # Merge all the summaries and write them out to the summaries_dir\n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n",
    "                                         sess.graph)\n",
    "\n",
    "    validation_writer = tf.summary.FileWriter(\n",
    "        FLAGS.summaries_dir + '/validation')\n",
    "\n",
    "    # Set up all our weights to their initial default values.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Run the training for as many cycles as requested on the command line.\n",
    "    for i in range(FLAGS.how_many_training_steps):\n",
    "      # Get a batch of input bottleneck values, either calculated fresh every\n",
    "      # time with distortions applied, or from the cache stored on disk.\n",
    "        (train_bottlenecks,\n",
    "         train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "             sess, image_lists, FLAGS.train_batch_size, 'training',\n",
    "             FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "             decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "             FLAGS.architecture)\n",
    "      # Feed the bottlenecks and ground truth into the graph, and run a training\n",
    "      # step. Capture training summaries for TensorBoard with the `merged` op.\n",
    "        train_summary, _ = sess.run(\n",
    "          [merged, train_step],\n",
    "          feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                     ground_truth_input: train_ground_truth})\n",
    "        train_writer.add_summary(train_summary, i)\n",
    "\n",
    "        # Every so often, print out how well the graph is training.\n",
    "        is_last_step = (i + 1 == FLAGS.how_many_training_steps)\n",
    "        if (i % FLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "        train_accuracy, cross_entropy_value = sess.run(\n",
    "            [evaluation_step, cross_entropy],\n",
    "            feed_dict={bottleneck_input: train_bottlenecks,\n",
    "                       ground_truth_input: train_ground_truth})\n",
    "        tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %\n",
    "                        (datetime.now(), i, train_accuracy * 100))\n",
    "        tf.logging.info('%s: Step %d: Cross entropy = %f' %\n",
    "                        (datetime.now(), i, cross_entropy_value))\n",
    "        validation_bottlenecks, validation_ground_truth, _ = (\n",
    "            get_random_cached_bottlenecks(\n",
    "                sess, image_lists, FLAGS.validation_batch_size, 'validation',\n",
    "                FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "                decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "                FLAGS.architecture))\n",
    "        # Run a validation step and capture training summaries for TensorBoard\n",
    "        # with the `merged` op.\n",
    "        validation_summary, validation_accuracy = sess.run(\n",
    "            [merged, evaluation_step],\n",
    "            feed_dict={bottleneck_input: validation_bottlenecks,\n",
    "                       ground_truth_input: validation_ground_truth})\n",
    "        validation_writer.add_summary(validation_summary, i)\n",
    "        tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                        (datetime.now(), i, validation_accuracy * 100,\n",
    "                         len(validation_bottlenecks)))\n",
    "\n",
    "        # Store intermediate results\n",
    "        intermediate_frequency = FLAGS.intermediate_store_frequency\n",
    "\n",
    "        if (intermediate_frequency > 0 and (i % intermediate_frequency == 0)\n",
    "          and i > 0):\n",
    "        intermediate_file_name = (FLAGS.intermediate_output_graphs_dir +\n",
    "                                  'intermediate_' + str(i) + '.pb')\n",
    "        tf.logging.info('Save intermediate result to : ' +\n",
    "                        intermediate_file_name)\n",
    "        save_graph_to_file(sess, graph, intermediate_file_name)\n",
    "\n",
    "        # We've completed all our training, so run a final test evaluation on\n",
    "        # some new images we haven't used before.\n",
    "        test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "        get_random_cached_bottlenecks(\n",
    "            sess, image_lists, FLAGS.test_batch_size, 'testing',\n",
    "            FLAGS.bottleneck_dir, FLAGS.image_dir, jpeg_data_tensor,\n",
    "            decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "            FLAGS.architecture))\n",
    "        test_accuracy, predictions = sess.run(\n",
    "        [evaluation_step, prediction],\n",
    "        feed_dict={bottleneck_input: test_bottlenecks,\n",
    "                   ground_truth_input: test_ground_truth})\n",
    "        tf.logging.info('Final test accuracy = %.1f%% (N=%d)' %\n",
    "                    (test_accuracy * 100, len(test_bottlenecks)))\n",
    "\n",
    "        if FLAGS.print_misclassified_test_images:\n",
    "        tf.logging.info('=== MISCLASSIFIED TEST IMAGES ===')\n",
    "        for i, test_filename in enumerate(test_filenames):\n",
    "        if predictions[i] != test_ground_truth[i]:\n",
    "          tf.logging.info('%70s  %s' %\n",
    "                          (test_filename,\n",
    "                           list(image_lists.keys())[predictions[i]]))\n",
    "\n",
    "        # Write out the trained graph and labels with the weights stored as\n",
    "        # constants.\n",
    "        save_graph_to_file(sess, graph, FLAGS.output_graph)\n",
    "        with gfile.FastGFile(FLAGS.output_labels, 'w') as f:\n",
    "        f.write('\\n'.join(image_lists.keys()) + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
